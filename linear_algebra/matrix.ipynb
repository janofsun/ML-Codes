{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformation Matrix from Basis B to C\n",
    "\n",
    "Given basis vectors in two different bases B and C for R^3, write a Python function to compute the transformation matrix P from basis B to C.\n",
    "\n",
    "Example:\n",
    "        \n",
    "        B = [[1, 0, 0], \n",
    "             [0, 1, 0], \n",
    "             [0, 0, 1]]\n",
    "        \n",
    "        C = [[1, 2.3, 3], \n",
    "             [4.4, 25, 6], \n",
    "             [7.4, 8, 9]]\n",
    "        \n",
    "        output: [[-0.6772, -0.0126, 0.2342],\n",
    "                [-0.0184, 0.0505, -0.0275],\n",
    "                [0.5732, -0.0345, -0.0569]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform from basis  $B$  to basis  $C$ , we need to express the vectors of basis  B  in terms of the coordinates in basis  $C$ . This involves representing each vector of  $B$  in the basis  $C$ .\n",
    "\n",
    "If we have a transformation matrix  $P$ , its columns are the coordinates of the vectors of  $B$  in terms of the basis  $C$ , and can be represented as:\n",
    "\n",
    "\n",
    "$P = \\left[ [b_1]_C \\quad [b_2]_C \\quad [b_3]_C \\right]$\n",
    "\n",
    "where $[b_1]_C$ represents the coordinates of basis vector  $b_1$  in basis  $C$ , and so on.\n",
    "\n",
    "Why is  $P$  equal to  $C^{-1} B$  and not  $B^{-1} C$ ?\n",
    "\n",
    "\t•\tTransformation matrix from basis  B  to the standard basis: If you know the coordinates relative to basis  B , and you want to convert them to the standard basis, you need to multiply by the matrix  B , where the columns are the vectors of basis  B :\n",
    "\n",
    "$$\n",
    "v_{\\text{standard}} = B v_B\n",
    "$$\n",
    "\n",
    "\t•\tTransformation matrix from basis  C  to the standard basis: Similarly, for basis  C , to transform from the standard basis to basis  C , you need to multiply by  C^{-1} :\n",
    "\n",
    "$$\n",
    "v_C = C^{-1} v_{\\text{standard}}\n",
    "$$\n",
    "\n",
    "\t•\tTransformation from basis  B  to basis  C : To transform from basis  B  to basis  C , you first need to convert from basis  B  to the standard basis, and then from the standard basis to basis  C . Thus:\n",
    "\n",
    "$$\n",
    "v_C = C^{-1} v_{\\text{standard}} = C^{-1} B v_B\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def transform_basis(B, C):\n",
    "    C = np.array(C)\n",
    "    B = np.array(B)\n",
    "    C_inv = np.linalg.inv(C)\n",
    "    P = np.dot(C_inv, B)\n",
    "    return P.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrix Transformation\n",
    "\n",
    "Example:\n",
    "        \n",
    "        input: A = [[1, 2], [3, 4]], T = [[2, 0], [0, 2]], S = [[1, 1], [0, 1]]\n",
    "        \n",
    "        output: [[0.5,1.5],[1.5,3.5]]\n",
    "        \n",
    "        reasoning: The matrices T and S are used to transform matrix A by computing $T^{-1}AS$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_matrix(A: list[list[int|float]], T: list[list[int|float]], S: list[list[int|float]]) -> list[list[int|float]]:\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    A = np.array(A)\n",
    "    T = np.array(T)\n",
    "    S = np.array(S)\n",
    "    \n",
    "    # Check if the matrices T and S are invertible\n",
    "    if np.linalg.det(T) == 0 or np.linalg.det(S) == 0:\n",
    "        raise ValueError(\"The matrices T and/or S are not invertible.\")\n",
    "    \n",
    "    # Compute the inverses of T and S\n",
    "    T_inv = np.linalg.inv(T)\n",
    "    \n",
    "    # Perform the matrix transformation\n",
    "    transformed_matrix = T_inv.dot(A).dot(S)\n",
    "    \n",
    "    return transformed_matrix.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate 2x2 Matrix Inverse\n",
    "\n",
    "Example:\n",
    "        \n",
    "        input: matrix = [[4, 7], [2, 6]]\n",
    "        \n",
    "        output: [[0.6, -0.7], [-0.2, 0.4]]\n",
    "        \n",
    "        reasoning: The inverse of a 2x2 matrix [a, b], [c, d] is given by (1/(ad-bc)) * [d, -b], [-c, a], provided ad-bc is not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_2x2(matrix: list[list[float]]) -> list[list[float]]:\n",
    "    a, b, c, d = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]\n",
    "    determinant = a * d - b * c\n",
    "    if determinant == 0:\n",
    "        return None\n",
    "    inverse = [[d/determinant, -b/determinant], [-c/determinant, a/determinant]]\n",
    "    return inverse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Covariance Matrix\n",
    "\n",
    "A covariance matrix is a matrix that shows the covariance between different features in a dataset. Covariance measures how much two random variables change together.\n",
    "$${Cov}(X_i, X_j) = \\frac{1}{n - 1} \\sum_{k=1}^{n} \\left( X_i[k] - \\mu_i \\right) \\left( X_j[k] - \\mu_j \\right)$$\n",
    "\n",
    "- If covariance > 0: As one feature increases, the other tends to increas\n",
    "- If covariance < 0: As one feature increases, the other tends to decrease.\n",
    "- If covariance = 0: The two features are independent of each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance_matrix(vectors: list[list[float]]) -> list[list[float]]:\n",
    "\t#Each vector in vectors corresponds to a feature.\n",
    "\tn_features = len(vectors)\n",
    "\t#Each feature vector contains observations (data points) for that specific feature.\n",
    "\tn_observations = len(vectors[0])\n",
    "\tcovariance_matrix = [[0]*n_features for i in range(n_features)]\n",
    "\tmeans_features = [sum(feature)/n_observations for feature in vectors]\n",
    "\t\n",
    "\tfor i in range(n_features):\n",
    "\t\tfor k in range(i, n_features):\n",
    "\t\t\tcovariance = sum([(vectors[i][j]-means_features[i])*(vectors[k][j]-means_features[k]) for j in range(n_observations)]) / (n_observations-1)\n",
    "\t\t\tcovariance_matrix[i][k] = covariance_matrix[k][i] = covariance\t\t\t\t  \n",
    "\t\n",
    "\treturn covariance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Correlation Matrix\n",
    "\n",
    "The correlation matrix is derived from the covariance matrix by normalizing the covariance values by the standard deviations of the respective features:\n",
    "\n",
    "\n",
    "$${Corr}(X_i, X_j) = \\frac{\\text{Cov}(X_i, X_j)}{\\sqrt{\\text{Var}(X_i)} \\cdot \\sqrt{\\text{Var}(X_j)}}$$\n",
    "\n",
    "Covariance is affected by the scale (units) of the variables, while correlation standardizes this relationship. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_matrix(X, Y=None):\n",
    "\tif not Y: Y=X\n",
    "\tn_samples, n_features = X.shape\n",
    "\tdef matrix_std_calculator(matrix):\n",
    "\t\tscaled_matrix = matrix-np.mean(matrix, axis=0) # matrix - [1,n_features]\n",
    "\t\treturn np.sqrt(np.mean(scaled_matrix**2, axis=0))\n",
    "\tscaled_X = X-np.mean(X,axis=0)\n",
    "\tscaled_Y = Y-np.mean(Y,axis=0)\n",
    "\tcov_matrix = (1/n_samples)*(scaled_X.T@scaled_Y)\n",
    "\tstd_X = matrix_std_calculator(X).reshape(-1,1)\n",
    "\tstd_Y = matrix_std_calculator(Y).reshape(1,-1)\n",
    "\tcorrelation_matrix = np.divide(cov_matrix, std_X@std_Y)\n",
    "\t\n",
    "\treturn correlation_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Eigenvalues of a Matrix\n",
    "\n",
    "\n",
    "$${det}(A - \\lambda I) = 0$$\n",
    "$${det}\\begin{pmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{pmatrix} = 0$$\n",
    "$$(a - \\lambda)(d - \\lambda) - bc = 0$$\n",
    "$$\\lambda^2 - (a + d)\\lambda + (ad - bc) = 0$$\n",
    "$$ \\lambda^2 - (a + d)\\lambda + (ad - bc) = 0$$\n",
    "- ${trace} = a + d$  (the sum of the diagonal elements),\n",
    "- ${determinant} = ad - bc$  (the determinant of the matrix).\n",
    "\n",
    "$$\\lambda_1, \\lambda_2 = \\frac{\\text{trace} \\pm \\sqrt{\\text{trace}^2 - 4 \\cdot \\text{determinant}}}{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eigenvalues(matrix: list[list[float|int]]) -> list[float]:\n",
    "\ta, b, c, d = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]\n",
    "\ttrace = a+d\n",
    "\tdet = a*d-b*c\n",
    "\tdiscriminant = trace**2-4*det\n",
    "\tlambda1 = (trace+discriminant**0.5)/2\n",
    "\tlambda2 = (trace-discriminant**0.5)/2\n",
    "\treturn [lambda1, lambda2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Vector to Diagonal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_diagonal(x):\n",
    "\tidentity_matrix = np.identity(np.size(x))\n",
    "\treturn identity_matrix*x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw11785",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
